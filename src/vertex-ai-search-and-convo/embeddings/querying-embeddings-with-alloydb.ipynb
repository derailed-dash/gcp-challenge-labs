{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3032a8-ffef-4c8d-87cb-e49abd8038e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install numpy pandas pgvector langchain transformers google-cloud-aiplatform psycopg2-binary shapely==2.0.6 langchain-core langchain-community langchain-google-vertexai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73947dbf-4272-4cb6-93aa-1690a0d663f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd110b3-510c-4363-a807-0557397633a4",
   "metadata": {},
   "source": [
    "## Download and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd77304-ceb1-4f47-924e-37a81b9a08cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-02-3482f55918a6\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae264e8a-2c4a-4c6d-a0ad-ee4eeed0ba8e",
   "metadata": {},
   "source": [
    "Read the CSV dataset into a pandas DataFrame, and saves the DataFrame to a table named products in the AlloyDB cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c471f54-3997-4ed0-80e0-1ea6be74ed8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully!\n",
      "('74a695e3675efc2aad11ed73c46db29b', 'Slip N Slide Triple Racer with Slide Boogies', 'Triple Racer Slip and Slide with Boogie Boards. The unit is 16 foot long. The unit has 3 sliding lanes.', 37.21)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 # library for PostgreSQL\n",
    "\n",
    "# Replace with your AlloyDB cluster credentials\n",
    "cluster_ip_address = \"10.102.0.2\"\n",
    "database_user = \"postgres\"\n",
    "database_password = \"postgres\"\n",
    "\n",
    "# Set environment variables for psql connection\n",
    "os.environ[\"PGHOST\"] = cluster_ip_address\n",
    "os.environ[\"PGUSER\"] = database_user\n",
    "os.environ[\"PGPASSWORD\"] = database_password\n",
    "\n",
    "# Establish a connection to the database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=cluster_ip_address,\n",
    "        user=database_user,\n",
    "        password=database_password\n",
    "    )\n",
    "    print(\"Connected to the database successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection error:\", e)\n",
    "exit(1)\n",
    "\n",
    "# Read the dataset from the URL\n",
    "DATASET_URL = \"https://github.com/GoogleCloudPlatform/python-docs-samples/raw/main/cloud-sql/postgres/pgvector/data/retail_toy_dataset.csv\"\n",
    "df = pd.read_csv(DATASET_URL)\n",
    "\n",
    "# Select desired columns and drop missing values\n",
    "df = df.loc[:, [\"product_id\", \"product_name\", \"description\", \"list_price\"]]\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the DataFrame to the AlloyDB cluster\n",
    "df.to_sql('products', con=f'postgresql://{cluster_ip_address}', if_exists='replace', index=False)\n",
    "\n",
    "# Retrieve data from the 'products' table\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM products\")\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "print(results[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a15eb-fde9-4ba4-8827-a94459ddaa7d",
   "metadata": {},
   "source": [
    "## Generate Vector Embeddings using a Text Embedding Model\n",
    "\n",
    "Preprocess product descriptions, generate vector embeddings for them, and store the embeddings along with other relevant data in a PostgreSQL database table for downstream analysis or applications.\n",
    "\n",
    "We import the RecursiveTextSplitter class from the LangChain library, which is used for splitting text into smaller chunks. Iterate through each row in the DataFrame df and extract the product ID and description from each row.\n",
    "\n",
    "Then, we will split each description into smaller chunks and will create a dictionary for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23670f07-75b4-4a67-9c10-8087b5231e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\".\", \"\\n\"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")\n",
    "max_documents = 60\n",
    "chunked = []\n",
    "for index, row in df.iterrows():\n",
    "    product_id = row[\"product_id\"]\n",
    "    desc = row[\"description\"]\n",
    "    splits = text_splitter.create_documents([desc])\n",
    "    if len(chunked) < max_documents:\n",
    "        for s in splits:\n",
    "            r = {\"product_id\": product_id, \"content\": s.page_content}\n",
    "            chunked.append(r)\n",
    "    else:\n",
    "        break\n",
    "print(len(chunked))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436ee86-eb03-4202-b620-f96d9f00f5ca",
   "metadata": {},
   "source": [
    "Process product descriptions from a dataset by splitting them into smaller chunks, sending them to Vertex AI for embedding generation, and storing the retrieved embeddings back into the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3092047-f576-4f62-bac0-f56080fac831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7e8697b5b7cdb5a40daf54caf1435cd5</td>\n",
       "      <td>Rock, paper, scissors is a great way to resolv...</td>\n",
       "      <td>[-0.012742510065436363, -0.017762525007128716,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7e8697b5b7cdb5a40daf54caf1435cd5</td>\n",
       "      <td>. Great for educational games, dice games, boa...</td>\n",
       "      <td>[-0.02675631456077099, -0.024180172011256218, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7de8b315b3cb91f3680eb5b88a20dcee</td>\n",
       "      <td>Turn any small bicycle into an instrument for ...</td>\n",
       "      <td>[-0.035151511430740356, -0.06757935136556625, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7de8b315b3cb91f3680eb5b88a20dcee</td>\n",
       "      <td>. Durable Construction: Steel brackets stand u...</td>\n",
       "      <td>[-0.043607085943222046, -0.03579239919781685, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7de8b315b3cb91f3680eb5b88a20dcee</td>\n",
       "      <td>. Tools required: Adjustable wrench. www.schwi...</td>\n",
       "      <td>[-0.03578212484717369, -0.04733877256512642, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  \\\n",
       "0  7e8697b5b7cdb5a40daf54caf1435cd5   \n",
       "1  7e8697b5b7cdb5a40daf54caf1435cd5   \n",
       "2  7de8b315b3cb91f3680eb5b88a20dcee   \n",
       "3  7de8b315b3cb91f3680eb5b88a20dcee   \n",
       "4  7de8b315b3cb91f3680eb5b88a20dcee   \n",
       "\n",
       "                                             content  \\\n",
       "0  Rock, paper, scissors is a great way to resolv...   \n",
       "1  . Great for educational games, dice games, boa...   \n",
       "2  Turn any small bicycle into an instrument for ...   \n",
       "3  . Durable Construction: Steel brackets stand u...   \n",
       "4  . Tools required: Adjustable wrench. www.schwi...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.012742510065436363, -0.017762525007128716,...  \n",
       "1  [-0.02675631456077099, -0.024180172011256218, ...  \n",
       "2  [-0.035151511430740356, -0.06757935136556625, ...  \n",
       "3  [-0.043607085943222046, -0.03579239919781685, ...  \n",
       "4  [-0.03578212484717369, -0.04733877256512642, 0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the vector embeddings for each chunk of text.\n",
    "# This code snippet may run for a few minutes.\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "\n",
    "embeddings = VertexAIEmbeddings(\"text-embedding-004\")\n",
    "\n",
    "# Helper function to retry failed API requests with exponential backoff.\n",
    "def retry_with_backoff(func, *args, retry_delay=5, backoff_factor=2, **kwargs):\n",
    "    max_attempts = 10\n",
    "    retries = 0\n",
    "    for i in range(max_attempts):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"error: {e}\")\n",
    "            retries += 1\n",
    "            wait = retry_delay * (backoff_factor**retries)\n",
    "            print(f\"Retry after waiting for {wait} seconds...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "batch_size = 5\n",
    "for i in range(0, len(chunked), batch_size):\n",
    "    request = [x[\"content\"] for x in chunked[i : i + batch_size]]\n",
    "    response = retry_with_backoff(embeddings.embed_documents, request)\n",
    "    # Store the retrieved vector embeddings for each chunk back.\n",
    "    for x, e in zip(chunked[i : i + batch_size], response):\n",
    "        x[\"embedding\"] = e\n",
    "\n",
    "# Store the generated embeddings in a pandas dataframe.\n",
    "product_embeddings = pd.DataFrame(chunked)\n",
    "product_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c264b3a-0a5e-437e-8a21-15d1d5d23992",
   "metadata": {},
   "source": [
    "Create a table called product_embeddings with columns for product IDs, text content, and vector embeddings. We will iterate through the product embeddings generated previously and insert or update them in the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dcb3fa8-7093-4cbf-8d23-ad57dfe59422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the 'product_embeddings' table successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "# AlloyDB cluster connection details (replace with your actual values)\n",
    "cluster_ip_address = \"10.102.0.2\"\n",
    "database_user = \"postgres\"\n",
    "database_password = \"postgres\"\n",
    "\n",
    "# Connect to AlloyDB cluster\n",
    "conn = psycopg2.connect(\n",
    "    host=cluster_ip_address,\n",
    "    user=database_user,\n",
    "    password=database_password\n",
    ")\n",
    "\n",
    "# Create cursor for executing SQL commands\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Ensure vector extension is installed\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n",
    "\n",
    "# Drop existing table (if it exists)\n",
    "cur.execute(\"DROP TABLE IF EXISTS product_embeddings\")\n",
    "\n",
    "# Create the `product_embeddings` table\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE product_embeddings(\n",
    "        product_id VARCHAR(1024) NOT NULL PRIMARY KEY,\n",
    "        content TEXT,\n",
    "        embedding vector(768)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Register the vector type\n",
    "register_vector(conn)\n",
    "\n",
    "# Store vector embeddings in the table\n",
    "for index, row in product_embeddings.iterrows():\n",
    "    cur.execute(\"SELECT EXISTS(SELECT 1 FROM product_embeddings WHERE product_id = %s)\", (row[\"product_id\"],))\n",
    "    if not cur.fetchone()[0]:  # Product ID doesn't exist, insert\n",
    "        cur.execute(\"INSERT INTO product_embeddings (product_id, content, embedding) VALUES (%s, %s, %s)\", (row[\"product_id\"], row[\"content\"], row[\"embedding\"]))\n",
    "    else:  # Product ID exists, update\n",
    "        cur.execute(\"UPDATE product_embeddings SET content = %s, embedding = %s WHERE product_id = %s\", (row[\"content\"], row[\"embedding\"], row[\"product_id\"]))\n",
    "\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"Created the 'product_embeddings' table successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d8194-a2c3-4980-9be2-1da80e021905",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Indexes for faster Similarity Search\n",
    "\n",
    "Vector indexes can significantly speed up similarity search operations and avoid the brute-force exact nearest neighbor search that is used by default.\n",
    "\n",
    "Pgvector comes with two types of indexes: hnsw and ivfflat.\n",
    "\n",
    "We build an HNSW index on product_embeddings table using cosine similarity metric for faster search based on descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d03fc7-d64a-4d71-b96c-57cfa7ce984c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created an HNSW Index successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "# AlloyDB cluster connection details (replace with your actual values)\n",
    "cluster_ip_address = \"10.102.0.2\"\n",
    "database_user = \"postgres\"\n",
    "database_password = \"postgres\"\n",
    "\n",
    "m = 24\n",
    "ef_construction = 100\n",
    "operator = \"vector_cosine_ops\"\n",
    "\n",
    "# Connect to AlloyDB cluster\n",
    "conn = psycopg2.connect(\n",
    "    host=cluster_ip_address,\n",
    "    user=database_user,\n",
    "    password=database_password\n",
    ")\n",
    "\n",
    "# Register the vector type\n",
    "register_vector(conn)\n",
    "\n",
    "# Create the HNSW index on the `product_embeddings` table\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "    f\"\"\"CREATE INDEX ON product_embeddings\n",
    "        USING hnsw(embedding {operator})\n",
    "        WITH (m = {m}, ef_construction = {ef_construction})\n",
    "    \"\"\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "print(\"Created an HNSW Index successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbcaa3-1eac-4cc8-8e37-79bd7d066362",
   "metadata": {},
   "source": [
    "Next, create an IVFFLAT index on the product_embeddings table using cosine similarity for swift similarity searches among product descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f7e86f-01c0-4730-9585-41e191abbbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created an IVFFLAT Index successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "# AlloyDB cluster connection details (replace with your actual values)\n",
    "cluster_ip_address = \"10.102.0.2\"\n",
    "database_user = \"postgres\"\n",
    "database_password = \"postgres\"\n",
    "\n",
    "lists = 100\n",
    "operator = \"vector_cosine_ops\"\n",
    "\n",
    "# Connect to AlloyDB cluster\n",
    "conn = psycopg2.connect(\n",
    "    host=cluster_ip_address,\n",
    "    user=database_user,\n",
    "    password=database_password\n",
    ")\n",
    "\n",
    "# Register the vector type\n",
    "register_vector(conn)\n",
    "\n",
    "# Create the IVFFLAT index on the `product_embeddings` table\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "    f\"\"\"CREATE INDEX ON product_embeddings\n",
    "        USING ivfflat(embedding {operator})\n",
    "        WITH (lists = {lists})\n",
    "    \"\"\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "print(\"Created an IVFFLAT Index successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4fd7b-edc0-48df-8fc9-ac3c6eb67e54",
   "metadata": {},
   "source": [
    "Now, we will conduct the similarity search. The provided code identifies products most relevant to the user's query based on their textual descriptions. To ensure relevant results, the code also filters based on the desired price range 25-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d223f6-d57e-4c87-9a93-b48d4c8141a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        product_name  list_price  \\\n",
      "0                    12\"-20\" Schwinn Training Wheels       28.17   \n",
      "1       Slip N Slide Triple Racer with Slide Boogies       37.21   \n",
      "2  Polaris 39-310 5-Liter Zippered Super Bag for ...       39.47   \n",
      "3  Sandbox Castle 2-in-1 Sand and Water Table wit...       60.49   \n",
      "4  Jensen S100T Commercial Tot Full Bucket Rubber...       90.18   \n",
      "\n",
      "                                         description  \n",
      "0  Turn any small bicycle into an instrument for ...  \n",
      "1  Triple Racer Slip and Slide with Boogie Boards...  \n",
      "2  Keep your pool water sparkling clean all seaso...  \n",
      "3  Package Includes Sandbox Castle 2-in-1 Sand an...  \n",
      "4  This is a fully enclosed one piece infant seat...  \n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import pandas as pd\n",
    "\n",
    "# AlloyDB cluster connection details (replace with your actual values)\n",
    "cluster_ip_address = \"10.102.0.2\"\n",
    "database_user = \"postgres\"\n",
    "database_password = \"postgres\"\n",
    "\n",
    "toy = \"playing card games\"\n",
    "min_price = 25\n",
    "max_price = 100\n",
    "\n",
    "# Connect to AlloyDB cluster\n",
    "conn = psycopg2.connect(\n",
    "    host=cluster_ip_address,\n",
    "    user=database_user,\n",
    "    password=database_password\n",
    ")\n",
    "\n",
    "# Register the vector type\n",
    "register_vector(conn)\n",
    "\n",
    "# Get the query embedding\n",
    "qe = embeddings.embed_query(\"toy\")\n",
    "\n",
    "# Perform the similarity search and filtering\n",
    "cur = conn.cursor()\n",
    "similarity_threshold = 0.1\n",
    "num_matches = 50\n",
    "# Pass 'qe' twice to match the number of placeholders in the query\n",
    "cur.execute(\n",
    "    \"\"\"\n",
    "    WITH vector_matches AS (\n",
    "        SELECT product_id, 1 - (embedding <=> %s::vector) AS similarity\n",
    "        FROM product_embeddings\n",
    "        WHERE 1 - (embedding <=> %s::vector) > %s\n",
    "        ORDER BY similarity DESC\n",
    "        LIMIT %s\n",
    "    )\n",
    "    SELECT product_name, list_price, description\n",
    "    FROM products\n",
    "    WHERE product_id IN (SELECT product_id FROM vector_matches)\n",
    "    AND list_price >= %s AND list_price <= %s\n",
    "    \"\"\",\n",
    "    (qe, qe, similarity_threshold, num_matches, min_price, max_price)\n",
    ")\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Process the results\n",
    "matches = []\n",
    "for r in results:\n",
    "    try:\n",
    "        list_price = round(float(r[2]), 2)  # Attempt conversion and rounding\n",
    "    except ValueError:\n",
    "        list_price = r[2] \n",
    "    matches.append({\n",
    "        \"product_name\": r[0],\n",
    "        \"list_price\": r[1],\n",
    "        \"description\": r[2]\n",
    "    })\n",
    "\n",
    "# Display the results\n",
    "matches_df = pd.DataFrame(matches)\n",
    "print(matches_df.head(5))\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388044e-5eb3-4030-bccc-b057ddbb9963",
   "metadata": {},
   "source": [
    "## LLMs and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16ef81-841f-4e28-b359-97d4533d41c7",
   "metadata": {},
   "source": [
    "### Use case 1: Building an AI-curated contextual hybrid search\n",
    "\n",
    "Combine natural language query text with regular relational filters to create a powerful hybrid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb38b43-a531-4a9e-9d8d-53931dd8bded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_query = \"Do you have a toy set that teaches numbers and letters to kids?\"  # @param {type:\"string\"}\n",
    "min_price = 20  # @param {type:\"integer\"}\n",
    "max_price = 100  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da941a00-9469-49fc-9074-23401c2ef09f",
   "metadata": {},
   "source": [
    "Generate the vector embedding for the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c20c74-5b7b-4777-a85d-e3a67cf13167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qe = embeddings.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f834d7-5ced-4443-b6a5-e20128bfa3a4",
   "metadata": {},
   "source": [
    "Use pgvector to find similar products. The pgvector similarity search operators provide powerful semantics to combine the vector search operation with regular query filters in a single SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5cefca7-4ffe-4ff8-bd59-0f4ac5d05aea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        product_name  list_price  \\\n",
      "0                    12\"-20\" Schwinn Training Wheels       28.17   \n",
      "1       Slip N Slide Triple Racer with Slide Boogies       37.21   \n",
      "2  Polaris 39-310 5-Liter Zippered Super Bag for ...       39.47   \n",
      "3  Sandbox Castle 2-in-1 Sand and Water Table wit...       60.49   \n",
      "4  Jensen S100T Commercial Tot Full Bucket Rubber...       90.18   \n",
      "\n",
      "                                         description  \n",
      "0  Turn any small bicycle into an instrument for ...  \n",
      "1  Triple Racer Slip and Slide with Boogie Boards...  \n",
      "2  Keep your pool water sparkling clean all seaso...  \n",
      "3  Package Includes Sandbox Castle 2-in-1 Sand an...  \n",
      "4  This is a fully enclosed one piece infant seat...  \n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "def main(user_query,min_price,max_price):\n",
    "    try:\n",
    "        # AlloyDB cluster connection details (replace with your actual values)\n",
    "        cluster_ip_address = \"10.102.0.2\"\n",
    "        database_user = \"postgres\"\n",
    "        database_password = \"postgres\"\n",
    "\n",
    "        # Connect to AlloyDB cluster\n",
    "        conn = psycopg2.connect(\n",
    "        host=cluster_ip_address,\n",
    "        user=database_user,\n",
    "        password=database_password)\n",
    "\n",
    "        # Register the vector type\n",
    "        register_vector(conn)\n",
    "\n",
    "        # Get the query embedding\n",
    "        qe = embeddings.embed_query(user_query)\n",
    "\n",
    "        # Perform the similarity search and filtering\n",
    "        cur = conn.cursor()\n",
    "        similarity_threshold = 0.1\n",
    "        num_matches = 50\n",
    "\n",
    "        # Pass 'qe' twice to match the number of placeholders in the query\n",
    "        cur.execute(\n",
    "                    \"\"\"\n",
    "                        WITH vector_matches AS (\n",
    "                        SELECT product_id, 1 - (embedding <=> %s::vector) AS similarity\n",
    "                        FROM product_embeddings\n",
    "                        WHERE 1 - (embedding <=> %s::vector) > %s\n",
    "                        ORDER BY similarity DESC\n",
    "                        LIMIT %s\n",
    "                )\n",
    "                SELECT product_name, list_price, description\n",
    "                FROM products\n",
    "                WHERE product_id IN (SELECT product_id FROM vector_matches)\n",
    "                AND list_price >= %s AND list_price <= %s\n",
    "                \"\"\",\n",
    "                (qe, qe, similarity_threshold, num_matches, min_price, max_price))\n",
    "        results = cur.fetchall()\n",
    "        # Process the results\n",
    "        matches = []\n",
    "        for r in results:\n",
    "            try:\n",
    "                list_price = round(float(r[2]), 2)  # Attempt conversion and rounding\n",
    "            except ValueError:\n",
    "                    list_price = r[2] \n",
    "                    matches.append({\n",
    "                        \"product_name\": r[0],\n",
    "                        \"list_price\": r[1],\n",
    "                        \"description\": r[2]\n",
    "                    })\n",
    "                    # Display the results\n",
    "        matches_df = pd.DataFrame(matches)\n",
    "        print(matches_df.head(5))\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during database operations: {e}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "    return\n",
    "\n",
    "# Call the main function (no need for asyncio in this context)\n",
    "main(\"Do you have a toy set that teaches numbers and letters to kids?\",25,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d49f3-1126-44e1-9409-f2f5acec6f67",
   "metadata": {},
   "source": [
    "Use LangChain to summarize and generate a high-quality prompt to answer the user query.\n",
    "\n",
    "After finding the similar products and their descriptions using pgvector, the next step is to use them for generating a prompt input for the LLM model. Since individual product descriptions can be very long, they may not fit within the specified input payload limit for an LLM model. The MapReduceChain from the LangChain framework is used to generate and combine short summaries of similarly matched products. The combined summaries are then used to build a high-quality prompt for an input to the LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ffb084-4ee4-43fa-b8de-5e9b5f670c14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The toy that is most relevant to the question is the **Sandbox Castle 2-in-1 Sand and Water Table with Beach Playset**. \n",
       "\n",
       "Here are the details of the toy:\n",
       "\n",
       "1. **Toy Name:** Sandbox Castle 2-in-1 Sand and Water Table with Beach Playset\n",
       "2. **Price:** $60.49\n",
       "3. **Features:**\n",
       "    - Includes 14-piece sand tools including watering can, shovel, rake, castle and shell sand molds, sailboat, and bridges. These tools can be used for imaginative play and to teach children about different shapes, sizes, and colors.\n",
       "    - This toy is an activity for indoor or outdoor play, making it a great option for learning and fun.\n",
       "    - The toy is small enough to take on trips, making it a portable option for learning. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using LangChain for summarization and efficient context building.\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import langchain_core\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = VertexAI(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "map_prompt_template = \"\"\"\n",
    "            You will be given a detailed description of a toy product.\n",
    "            This description is enclosed in triple backticks (```).\n",
    "            Using this description only, extract the name of the toy,\n",
    "            the price of the toy and its features.\n",
    "\n",
    "            ```{text}```\n",
    "            SUMMARY:\n",
    "            \"\"\"\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "                You will be given a detailed description of different toy products\n",
    "                enclosed in triple backticks (```) and a question enclosed in\n",
    "                double backticks(``).\n",
    "                Select one toy that is most relevant to answer the question.\n",
    "                Using that selected toy description, answer the following\n",
    "                question in as much detail as possible.\n",
    "                You should only use the information in the description.\n",
    "                Your answer should include the name of the toy, the price of the toy\n",
    "                and its features. Your answer should be less than 200 words.\n",
    "                Your answer should be in Markdown in a numbered list format.\n",
    "\n",
    "                Description:\n",
    "                ```{text}```\n",
    "\n",
    "                Question:\n",
    "                ``{user_query}``\n",
    "\n",
    "                Answer:\n",
    "                \"\"\"\n",
    "combine_prompt = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"text\", \"user_query\"]\n",
    ")\n",
    "\n",
    "docs = [Document(page_content=str(t)) for t in matches]\n",
    "chain = load_summarize_chain(\n",
    "    llm, chain_type=\"map_reduce\", map_prompt=map_prompt, combine_prompt=combine_prompt\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "output = chain.invoke({\n",
    "    \"input_documents\": docs,\n",
    "    \"user_query\": user_query,\n",
    "})\n",
    "\n",
    "# Extract the output_text\n",
    "answer = output.get('output_text', ' ')\n",
    "\n",
    "# Display the answer in Markdown format\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab50e3-4300-4b2d-9b6a-ed69b63aa0d9",
   "metadata": {},
   "source": [
    "### Use case 2: Adding AI-powered creative content generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a27b97-22c8-498d-88cf-687eec7683c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use knowledge from the existing dataset to generate new AI-powered content from an initial prompt.\n",
    "\n",
    "A third-party seller on the retail platform wants to use the AI-powered content generation to create a detailed description of their new bicycle product.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edec53d-0d1b-4187-82b2-5c2ac550547e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please fill in these values.\n",
    "creative_prompt = \"A bicycle with brand name 'Roadstar bike' for kids that comes with training wheels and helmet.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5fcef-3a12-472f-a136-3532b05077fe",
   "metadata": {},
   "source": [
    "Leverage the pgvector similarity search operator to find an existing product description that closely matches the new product specified in the initial prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5169d449-c754-49b1-a8aa-e36dde6a0e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Turn any small bicycle into an instrument for learning to ride with the Schwinn 12\"-20\" Training Wheels. They feature a slotted design to fit 12\" to 20\" bikes. The training wheels are easy to assemble, install and remove, so that when your little one is able to ride without assistance, you can take them off. These bicycle training wheels include steel brackets and rubber tires that can stand up to heavy use. Training Wheels, Fits 12 inches - 20 inches bicycles. Est. 1895. Durable Construction: Steel brackets stand up to heavy use. Customizable: Two sets of wheel decals included. Features: Fits Most Childrens Bicycles: Intended for 12 inch - 20 inch bicycles. Steel Brackets: Offer increased durability. Includes two sets of wheel decals: Learn how to ride in style - see images below. Easy to Adjust: Slotted design for size adjustment. Includes: One pair of training wheels, four decals, installation instructions, and all mounting hardware. Tools required: Adjustable wrench. www.schwinnbikes.com. Follow ride Schwinn on: Twitter. Facebook. Made in China. Training Wheels,Fits 12 inches - 20 inches bicycles. Est. 1895. Durable Construction: Steel brackets stand up to heavy use. Customizable: Two sets of wheel decals included. Features: Fits Most Childrens Bicycles: Intended for 12 inch - 20 inch bicycles. Steel Brackets: Offer increased durability. Includes two sets of wheel decals: Learn how to ride in style - see images below. Easy to Adjust: Slotted design for size adjustment. Includes: One pair of training wheels, four decals, installation instructions, and all mounting hardware. Tools required: Adjustable wrench. www.schwinnbikes.com. Follow ride Schwinn on: Twitter. Facebook. Made in China.']\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # AlloyDB cluster connection details\n",
    "        cluster_ip_address = \"10.102.0.2\"\n",
    "        database_user = \"postgres\"\n",
    "        database_password = \"postgres\"\n",
    "\n",
    "        # Connect to AlloyDB cluster\n",
    "        conn = psycopg2.connect(\n",
    "            host=cluster_ip_address,\n",
    "            user=database_user,\n",
    "            password=database_password\n",
    "        )\n",
    "\n",
    "        # Register the vector type\n",
    "        register_vector(conn)\n",
    "\n",
    "        # Get the query embedding\n",
    "        qe = embeddings.embed_query(creative_prompt)\n",
    "\n",
    "        # Print the query embedding for debugging\n",
    "\n",
    "        # Ensure qe is a non-empty vector\n",
    "        if not qe:\n",
    "            print(\"Error: The query embedding is empty.\")\n",
    "            return\n",
    "\n",
    "        # Create the embedding string\n",
    "        matches = []\n",
    "        similarity_threshold = 0.5 \n",
    "\n",
    "        # Perform the similarity search and filtering\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            WITH vector_matches AS (\n",
    "                SELECT product_id, 1 - (embedding <=> %s::vector) AS similarity\n",
    "                FROM product_embeddings\n",
    "                WHERE 1 - (embedding <=> %s::vector) > %s\n",
    "                ORDER BY similarity DESC\n",
    "                LIMIT 1\n",
    "            )\n",
    "            SELECT description FROM products\n",
    "            WHERE product_id IN (SELECT product_id FROM vector_matches)\n",
    "            \"\"\",\n",
    "            (qe, qe, similarity_threshold)\n",
    "        )\n",
    "\n",
    "        results = cur.fetchall()\n",
    "\n",
    "        # Process the results\n",
    "        for r in results:\n",
    "            matches.append(r[0])\n",
    "\n",
    "        if not matches:\n",
    "            print(\"No matches found.\")\n",
    "        else:\n",
    "            print(matches)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during database operations: {e}\")\n",
    "    finally:\n",
    "        # Close the connection if it was established\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Call the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571539ef-42f8-444d-bb87-63416d27ae5d",
   "metadata": {},
   "source": [
    "Use the existing matched product description as the prompt context to generate new creative output from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa65571d-eaea-47db-9772-eafca0361d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a description of the Roadstar Bike for kids: \n",
       "\n",
       "* **Roadstar Bike:** This stylish and durable bike is perfect for young riders learning to ride. It features a bright, colorful design with a sturdy frame that can handle the bumps and scrapes of childhood adventures. \n",
       "* **Training Wheels:**  The Roadstar Bike comes equipped with adjustable training wheels.  These wheels are easy to install and remove, allowing you to customize the bike as your child progresses.  \n",
       "* **Helmet:** Safety first!  The Roadstar Bike includes a matching helmet with fun graphics.  The helmet is adjustable for a snug and comfortable fit. \n",
       "* **Additional Features:** \n",
       "    * **Handlebar Grips:** Soft, comfortable grips for little hands.\n",
       "    * **Bell:**  Let everyone know you're coming!\n",
       "    * **Kickstand:** Easy to park and store. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "template = \"\"\"\n",
    "            You are given descriptions about some similar kind of toys in the context.\n",
    "            This context is enclosed in triple backticks (```).\n",
    "            Combine these descriptions and adapt them to match the specifications in\n",
    "            the initial prompt. All the information from the initial prompt must\n",
    "            be included. You are allowed to be as creative as possible,\n",
    "            and describe the new toy in as much detail. Your answer should be\n",
    "            in markdown in lists and less than 200 words.\n",
    "\n",
    "            Context:\n",
    "            ```{context}```\n",
    "\n",
    "            Initial Prompt:\n",
    "            {creative_prompt}\n",
    "\n",
    "            Answer:\n",
    "        \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"creative_prompt\"]\n",
    ")\n",
    "\n",
    "# Increase the `temperature` to allow more creative writing freedom.\n",
    "llm = VertexAI(model_name=\"gemini-1.5-flash\", temperature=0.7)\n",
    "\n",
    "# Assuming each dictionary in `matches` has a `description` key:\n",
    "context = \"\\n\".join(\n",
    "    match[\"description\"] for match in matches if isinstance(match, dict)\n",
    ")\n",
    "\n",
    "# Use RunnableSequence instead of LLMChain\n",
    "llm_chain = RunnableSequence(prompt | llm)\n",
    "\n",
    "# Invoke the chain\n",
    "answer = llm_chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"creative_prompt\": creative_prompt,\n",
    "})\n",
    "\n",
    "# Display the answer in Markdown format\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bff338-b02d-4e95-af3f-212d6a836dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
