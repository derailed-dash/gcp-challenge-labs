{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18d3ed-1bf9-45b4-b3d9-51c8c31f27c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                        google-cloud-storage \\\n",
    "                        'google-cloud-bigquery[pandas]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c929c-da29-4589-80d1-b3280050e30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "# Restart kernel\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47a6583-6c46-44c7-9218-839a84340784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set env vars\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-east4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32c0ad-fc09-4cb6-bab3-72db52fa9781",
   "metadata": {},
   "source": [
    "## Initialise Vertex AI Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f752c764-2df5-40c5-b31f-5d6af59653bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project = PROJECT_ID,\n",
    "              location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163a078-dcd5-4280-b6b3-99ff93c30d9d",
   "metadata": {},
   "source": [
    "## Prepare Data in BigQuery\n",
    "\n",
    "The [StackOverflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) is a BQ mirror of Stack Overflow public dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19bc7e4e-b470-4446-897e-5516e810dfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any, Generator\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa7e425-40d6-45be-b7d9-b6fbbba16a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query to retrieve data from public Stack Overflow dataset\n",
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT distinct q.id, q.title, q.body\n",
    "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` where Score>0 ORDER BY View_Count desc) AS q\n",
    "        LIMIT {limit} OFFSET {offset};\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e85950-ecf5-4d88-a794-25223034b7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the data in chunks to make it manageable in memory\n",
    "def query_bigquery_chunks(max_rows: int, rows_per_chunk: int, start_chunk: int = 0) -> Generator[pd.DataFrame, Any, None]:\n",
    "    for offset in range(start_chunk, max_rows, rows_per_chunk):\n",
    "        query = QUERY_TEMPLATE.format(limit=rows_per_chunk, offset=offset)\n",
    "        query_job = client.query(query)\n",
    "        rows = query_job.result()\n",
    "        df = rows.to_dataframe()\n",
    "        df[\"title_with_body\"] = df.title + \"\\n\" + df.body\n",
    "        yield df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2794a15-b4d4-4a67-94b5-9365eaeb856b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>title_with_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13052878</td>\n",
       "      <td>emacs 24 c++ auto-indentation broken</td>\n",
       "      <td>&lt;p&gt;I'm running Emacs 24 on Ubuntu 10.04, codin...</td>\n",
       "      <td>emacs 24 c++ auto-indentation broken\\n&lt;p&gt;I'm r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12727898</td>\n",
       "      <td>UIKeyboard avoidance and Auto Layout</td>\n",
       "      <td>&lt;p&gt;Given the focus on Auto Layout in iOS 6, an...</td>\n",
       "      <td>UIKeyboard avoidance and Auto Layout\\n&lt;p&gt;Given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12848712</td>\n",
       "      <td>Changed project name in Xcode causing naming e...</td>\n",
       "      <td>&lt;p&gt;My old name consisted of a camel case type ...</td>\n",
       "      <td>Changed project name in Xcode causing naming e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12829700</td>\n",
       "      <td>Android Unit Testing: Bundle/Parcelable</td>\n",
       "      <td>&lt;p&gt;How do you unit test Parcelable?  I created...</td>\n",
       "      <td>Android Unit Testing: Bundle/Parcelable\\n&lt;p&gt;Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12680080</td>\n",
       "      <td>python enums with attributes</td>\n",
       "      <td>&lt;p&gt;Consider:&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;class Item:\\n   d...</td>\n",
       "      <td>python enums with attributes\\n&lt;p&gt;Consider:&lt;/p&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  13052878               emacs 24 c++ auto-indentation broken   \n",
       "1  12727898               UIKeyboard avoidance and Auto Layout   \n",
       "2  12848712  Changed project name in Xcode causing naming e...   \n",
       "3  12829700            Android Unit Testing: Bundle/Parcelable   \n",
       "4  12680080                       python enums with attributes   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>I'm running Emacs 24 on Ubuntu 10.04, codin...   \n",
       "1  <p>Given the focus on Auto Layout in iOS 6, an...   \n",
       "2  <p>My old name consisted of a camel case type ...   \n",
       "3  <p>How do you unit test Parcelable?  I created...   \n",
       "4  <p>Consider:</p>\\n<pre><code>class Item:\\n   d...   \n",
       "\n",
       "                                     title_with_body  \n",
       "0  emacs 24 c++ auto-indentation broken\\n<p>I'm r...  \n",
       "1  UIKeyboard avoidance and Auto Layout\\n<p>Given...  \n",
       "2  Changed project name in Xcode causing naming e...  \n",
       "3  Android Unit Testing: Bundle/Parcelable\\n<p>Ho...  \n",
       "4  python enums with attributes\\n<p>Consider:</p>...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dataframe of 1000 riows for demo purposes\n",
    "df = next(query_bigquery_chunks(max_rows=1000, rows_per_chunk=1000))\n",
    "\n",
    "# Examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a893d0c-c42a-458b-8fc2-92e6a0e13aef",
   "metadata": {},
   "source": [
    "## Create Text Embeddings from BigQuery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df838ab-3d6e-47df-a13e-b451e62c9092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "# Load the Vertex AI \"Embeddings for Text\" model\n",
    "model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4540d5-354e-4cb8-a133-b6341409a20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define an embedding function that uses the model\n",
    "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        embeddings = model.get_embeddings(sentences)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc0595ef-4f11-43a5-a701-5e01456b494f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Generator, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Generator function to yield batches of sentences\n",
    "def generate_batches(\n",
    "    sentences: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        yield sentences[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef04fa7a-16ca-4e33-b4eb-7bdf6e832ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_text_to_embedding_batched(\n",
    "    sentences: List[str], api_calls_per_second: int = 10, batch_size: int = 5\n",
    ") -> Tuple[List[bool], np.ndarray]:\n",
    "\n",
    "    embeddings_list: List[List[float]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(sentences, batch_size)\n",
    "\n",
    "    seconds_per_job = 1 / api_calls_per_second\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(\n",
    "            batches, total=math.ceil(len(sentences) / batch_size), position=0\n",
    "        ):\n",
    "            futures.append(\n",
    "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
    "            )\n",
    "            time.sleep(seconds_per_job) # for rate limiting - in Prod, we would do something more sophisticated\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "\n",
    "    is_successful = [\n",
    "        embedding is not None for sentence, embedding in zip(sentences, embeddings_list)\n",
    "    ]\n",
    "    embeddings_list_successful = np.squeeze(\n",
    "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
    "    )\n",
    "    return is_successful, embeddings_list_successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa646853-41e5-4485-b84d-fa325fbea262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a31707021b94ed29ed384a93480857c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode a subset of questions for validation\n",
    "questions = df.title.tolist()[:500]\n",
    "is_successful, question_embeddings = encode_text_to_embedding_batched(\n",
    "    sentences=df.title.tolist()[:500]\n",
    ")\n",
    "\n",
    "# Filter for successfully embedded sentences\n",
    "questions = np.array(questions)[is_successful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8441ae1b-c018-4dd7-9c6c-562ca341fe51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Save the dimension size for later usage when creating the Vertex AI Vector Search index.\n",
    "DIMENSIONS = len(question_embeddings[0])\n",
    "\n",
    "print(DIMENSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ad707-a2c7-4ee0-afdc-51cb207a1541",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sort questions by order of similarity\n",
    "\n",
    "- 0 means very different\n",
    "- 1 means very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d8e11cb-dde8-4a43-b1a1-cfd7db2c7ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query question = Setting \"an informative User-Agent string\" in getURL\n",
      "\t0: Setting \"an informative User-Agent string\" in getURL: 0.9999981819202963\n",
      "\t1: Getting JSON data: 0.5050393007723325\n",
      "\t2: Is it possible to have open-uri maintain the extension?: 0.4645424495835494\n",
      "\t3: Is it possible to return HTTP response code to the browser using pl/sql?: 0.4431916192040807\n",
      "\t4: UploadStringAsync CallBack Return Type: 0.4378561185815355\n",
      "\t5: handle jsonp with varnish: 0.4326099188977214\n",
      "\t6: getting name value pairs(in decoded format) from the posted form: 0.42829365460803087\n",
      "\t7: 301 redirect vs canonical links?: 0.4216442393417451\n",
      "\t8: Open remote file and write to it: 0.4213806729405419\n",
      "\t9: How to to set a background image on a navigation bar?: 0.41662236864106983\n",
      "\t10: TinyMCE SCRIPT5: Access is denied. Typical cross-domain error on same domain: 0.4152998579250148\n",
      "\t11: php sprintf replace multiple placeholders with one value: 0.4059620871040117\n",
      "\t12: mod_rewrite for redirecting a directory to a top level domain: 0.4052406823618905\n",
      "\t13: How to get \"printf\" messages written in NDK application?: 0.4042352004366461\n",
      "\t14: Connecting with Google Picasa -> Delphi 7: 0.4013857939731559\n",
      "\t15: How to support multiple custom cache manifest for offline use, on a user by user basis?: 0.3887073218304812\n",
      "\t16: Java: regex - how do i get the first quote text: 0.3881258512990585\n",
      "\t17: Get data from based on schedule: 0.3857536516615352\n",
      "\t18: Using PrintDocument to print multiple pages: 0.38447335320740217\n",
      "\t19: Solr error, unknown field: 0.38410730811590643\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "question_index = random.randint(0, 99)\n",
    "\n",
    "print(f\"Query question = {questions[question_index]}\")\n",
    "\n",
    "# Get similarity scores for each embedding by using dot-product.\n",
    "scores = np.dot(question_embeddings[question_index], question_embeddings.T)\n",
    "\n",
    "# Print top 20 matches\n",
    "for index, (question, score) in enumerate(\n",
    "    sorted(zip(questions, scores), key=lambda x: x[1], reverse=True)[:20]\n",
    "):\n",
    "    print(f\"\\t{index}: {question}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437d692-c322-4b7a-9e6f-ecf88680059d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Embeddings in JSONL\n",
    "\n",
    "- I.e. each embedding dictionary written as an individual JSON object on its own line.\n",
    "- Write embeddings in batches to prevent out-of-memory errors.\n",
    "\n",
    "This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b04340ab-139d-4b1f-a73d-37c281016bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings directory: /var/tmp/tmp975fktgy\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file_path = Path(tempfile.mkdtemp())\n",
    "\n",
    "print(f\"Embeddings directory: {embeddings_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10857b9a-b7e8-458a-8a6a-c090db6bfa50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d407625d09164fd2929e19dd149bb020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunk of rows from BigQuery:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a820d6dfb0e84379aad7d3fe97b49575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faae5b63fb84460590a5d321606b1a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c137e5017b164ae994ae4f7f467233a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb281a726d254f66913c32cf84d1bc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec44e44bd4b4b1cbd1772d5ae1fa2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "# Write embeddings for 5000 questions, split into 1000 question chunks.\n",
    "BQ_NUM_ROWS = 5000\n",
    "BQ_CHUNK_SIZE = 1000\n",
    "BQ_NUM_CHUNKS = math.ceil(BQ_NUM_ROWS / BQ_CHUNK_SIZE)\n",
    "\n",
    "START_CHUNK = 0\n",
    "\n",
    "# Create a rate limit of 300 requests per minute. Adjust this depending on your quota.\n",
    "API_CALLS_PER_SECOND = 300 / 60\n",
    "# According to the docs, each request can process 5 instances per request\n",
    "ITEMS_PER_REQUEST = 5\n",
    "\n",
    "# Loop through each generated dataframe, convert\n",
    "for i, df in tqdm(\n",
    "    enumerate(\n",
    "        query_bigquery_chunks(\n",
    "            max_rows=BQ_NUM_ROWS, rows_per_chunk=BQ_CHUNK_SIZE, start_chunk=START_CHUNK\n",
    "        )\n",
    "    ),\n",
    "    total=BQ_NUM_CHUNKS - START_CHUNK,\n",
    "    position=-1,\n",
    "    desc=\"Chunk of rows from BigQuery\",\n",
    "):\n",
    "    # Create a unique output file for each chunk\n",
    "    chunk_path = embeddings_file_path.joinpath(\n",
    "        f\"{embeddings_file_path.stem}_{i+START_CHUNK}.json\"\n",
    "    )\n",
    "    with open(chunk_path, \"a\") as f:\n",
    "        id_chunk = df.id\n",
    "\n",
    "        # Convert batch to embeddings\n",
    "        is_successful, question_chunk_embeddings = encode_text_to_embedding_batched(\n",
    "            sentences=df.title_with_body.to_list(),\n",
    "            api_calls_per_second=API_CALLS_PER_SECOND,\n",
    "            batch_size=ITEMS_PER_REQUEST,\n",
    "        )\n",
    "\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [str(value) for value in embedding],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            for id, embedding in zip(id_chunk[is_successful], question_chunk_embeddings)\n",
    "        ]\n",
    "        f.writelines(embeddings_formatted)\n",
    "\n",
    "        # Delete the DataFrame and any other large data structures\n",
    "        del df\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5976162-9775-4f3d-8a8b-f8dc6c418275",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload Embeddings to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef90e9fe-400e-4a70-8a7f-0bfd44e60884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-00-776bfcd5598f-unique/...\n",
      "Copying file:///var/tmp/tmp975fktgy/tmp975fktgy_0.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmp975fktgy/tmp975fktgy_1.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmp975fktgy/tmp975fktgy_2.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmp975fktgy/tmp975fktgy_3.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmp975fktgy/tmp975fktgy_4.json [Content-Type=application/json]...\n",
      "/ [5/5 files][  6.4 MiB/  6.4 MiB] 100% Done                                    \n",
      "Operation completed over 5 objects/6.4 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "BUCKET_URI = f\"gs://{PROJECT_ID}-unique\"\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}\n",
    "\n",
    "# Upload training data to a GCS bucket\n",
    "remote_folder = f\"{BUCKET_URI}/{embeddings_file_path.stem}/\"\n",
    "! gsutil -m cp -r {embeddings_file_path}/* {remote_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5545acc-d534-4f00-8640-f4869f8f56f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create an Index in Vertex AI Vector Search for the Uploading Embeddings\n",
    "\n",
    "Create the index by reading the embeddings from the GCS bucket. This can take a long time. Maybe an hour!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b159fb5-c318-4bbe-91d0-6cf15e806995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"stack_overflow\"\n",
    "DESCRIPTION = \"question titles and bodies from stackoverflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50890723-aa36-4830-9dcb-0d1e089b7e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/279850850042/locations/us-east4/indexes/3687612465979326464/operations/2162634368474939392\n",
      "MatchingEngineIndex created. Resource name: projects/279850850042/locations/us-east4/indexes/3687612465979326464\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/279850850042/locations/us-east4/indexes/3687612465979326464')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n",
    "\n",
    "DIMENSIONS = 768\n",
    "\n",
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=remote_folder,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=150,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=80,\n",
    "    description=DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "074017d2-b43b-4323-ba60-80c0b4febd91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/279850850042/locations/us-east4/indexes/3687612465979326464'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e84d09ec-1ae5-4552-8c95-869366dd8ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve an existing index by name\n",
    "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6677462-1d25-4b29-a2c8-0fc43538fc94",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and Deploy an IndexEndpoint to that it can be accesssed by API\n",
    "\n",
    "Creating the IndexEndpoint is quick, but deploying can take about 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66a94a08-9d2c-4440-88f1-3ff1e460d656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/279850850042/locations/us-east4/indexEndpoints/5762962653639081984/operations/4585570968000266240\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/279850850042/locations/us-east4/indexEndpoints/5762962653639081984\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/279850850042/locations/us-east4/indexEndpoints/5762962653639081984')\n"
     ]
    }
   ],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    description=DISPLAY_NAME,\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180914dd-8f61-49ab-9e56-b318952fb1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/279850850042/locations/us-east4/indexEndpoints/5762962653639081984\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/279850850042/locations/us-east4/indexEndpoints/5762962653639081984/operations/4184750601164292096\n"
     ]
    }
   ],
   "source": [
    "# Deploy the index to the created endpoint\n",
    "DEPLOYED_INDEX_ID = \"deployed_index_id_unique\"\n",
    "\n",
    "DEPLOYED_INDEX_ID\n",
    "\n",
    "\n",
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5aad6-35b3-492f-a76c-dd3bfbe667b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_vectors = sum(\n",
    "    aiplatform.MatchingEngineIndex(\n",
    "        deployed_index.index\n",
    "    )._gca_resource.index_stats.vectors_count\n",
    "    for deployed_index in my_index_endpoint.deployed_indexes\n",
    ")\n",
    "\n",
    "print(f\"Expected: {BQ_NUM_ROWS}, Actual: {number_of_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b6fba-121e-4f73-87f9-cb1963ce4af0",
   "metadata": {},
   "source": [
    "## Query Against the Deployed Index to Find Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e6b89-5681-4ceb-9e37-d5c22c40d7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create embedding for test question\n",
    "test_embeddings = encode_texts_to_embeddings(sentences=[\"Install GPU for Tensorflow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0404aa-7a0b-40e3-b70e-760c2b2d0994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the query to retrieve similar embeddings\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBOURS,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2d3fa-8263-48b1-861b-6a1898e73ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the retrieved results are relevant by actually looking at the Stack Overflow links\n",
    "for match_index, neighbor in enumerate(response[0]):\n",
    "    print(f\"https://stackoverflow.com/questions/{neighbor.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca594e-d5e2-4b1a-8ca7-c43f08e9a9a8",
   "metadata": {},
   "source": [
    "## Environment Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba0de5a-7211-41b4-933a-fd47a2dff1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)\n",
    "\n",
    "# Delete indexes\n",
    "tree_ah_index.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
