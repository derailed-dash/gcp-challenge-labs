{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51dc795-996b-4a21-8c8b-2159b5d41daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade --user google-cloud-aiplatform google-cloud-discoveryengine google-cloud-storage google-cloud-bigquery[pandas] google-cloud-bigquery-storage pandas ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ba72b-5d43-4557-8c0b-f1c665b468ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45464406-fb74-41f7-b9a3-1aac22188ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1ab78-0ca0-4538-a689-7dae2efce5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.api_core.exceptions import GoogleAPICallError\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import discoveryengine_v1alpha as discoveryengine\n",
    "from google.cloud import storage\n",
    "\n",
    "from tqdm import tqdm  # to show a progress bar\n",
    "\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6708499-430c-4b80-9f55-73fa772aae5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce5b99-bc31-48fb-b77c-ffe43ef5db17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define project information for Vertex AI\n",
    "PROJECT_ID = \"qwiklabs-gcp-03-c75e2f9727f1\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08758524-b862-476b-908e-5a31b42a484d",
   "metadata": {},
   "source": [
    "## Create Embeddings with Vertex AI\n",
    "\n",
    "We will be using the [Stack Overflow public dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) hosted on BigQuery table bigquery-public-data.stackoverflow.posts_questions. This is a very big dataset with 23 million rows that doesn't fit into memory. We are going to limit it to 500 rows for this lab.\n",
    "\n",
    "Here we will:\n",
    "\n",
    "- Fetch the data from BigQuery\n",
    "- Concat the Title and Body\n",
    "- Create embeddings from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e3cbc-9d2d-48a1-aaf0-66c4f7f08375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  DISTINCT \n",
    "  q.id,\n",
    "  q.title,\n",
    "  q.body,\n",
    "  q.answer_count,\n",
    "  q.comment_count,\n",
    "  q.creation_date,\n",
    "  q.last_activity_date,\n",
    "  q.score,\n",
    "  q.tags,\n",
    "  q.view_count\n",
    "FROM\n",
    "  `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "WHERE\n",
    "  q.score > 0\n",
    "ORDER BY\n",
    "  q.view_count DESC\n",
    "LIMIT\n",
    "  500;\n",
    "\"\"\"\n",
    "\n",
    "# Load the BQ Table into a Pandas Dataframe\n",
    "df = bq_client.query(query).result().to_dataframe()\n",
    "\n",
    "# Convert ID to String\n",
    "df[\"id\"] = df[\"id\"].apply(str)\n",
    "\n",
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb1f66-8f8b-444b-b60e-98be512cc36e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the text embeddings model\n",
    "model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123138d-26cf-40a8-ba31-cd59676f3c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get embeddings for a list of texts\n",
    "def get_embeddings_wrapper(texts, batch_size: int = 5) -> List:\n",
    "    embs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        # Create embeddings optimized for document retrieval\n",
    "        # (supported in textembedding-gecko@002 and later)\n",
    "        result = model.get_embeddings(\n",
    "            [\n",
    "                TextEmbeddingInput(text=text, task_type=\"RETRIEVAL_DOCUMENT\")\n",
    "                for text in texts[i : i + batch_size]\n",
    "            ]\n",
    "        )\n",
    "        embs.extend([e.values for e in result])\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56476941-1f85-4033-b981-7bc7e96c76bf",
   "metadata": {},
   "source": [
    "Now modify the previously loaded DataFrame (df) by combining the title and body columns into a new title_body column. Then, it uses the get_embeddings_wrapper function to obtain text embeddings for each combined title and body, and the resulting embeddings are added as a new embedding column to the DataFrame. Finally, the first few rows of the updated DataFrame are displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a3eaa-d72f-49a8-b3ca-db338f143fc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Here we may have a quota limit problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8151a53-204a-44cf-a3f4-3be2ea2a8088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"title_body\"] = df[\"title\"] + \"\\n\" + df[\"body\"]\n",
    "\n",
    "df = df.assign(embedding=get_embeddings_wrapper(df.title_body))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554d71c-be96-41b4-aef6-8b14fd0ff5f3",
   "metadata": {},
   "source": [
    "## Scrape HTML from Question Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ddfefb-d07f-4c12-9f29-4bc17f59ec3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"qwiklabs-gcp-03-c75e2f9727f1\"\n",
    "BUCKET_URI = \"gs://qwiklabs-gcp-03-c75e2f9727f1\"\n",
    "REGION = \"us-west1\"\n",
    "PROJECT_ID = \"qwiklabs-gcp-03-c75e2f9727f1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d71179-f391-4e33-8abf-0fa46e93d976",
   "metadata": {},
   "source": [
    "Create GCS storage bucket and create directories in the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96dc8e6-c8ad-4973-a284-d1bbe7efd183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc000a-2e0a-4f20-8498-dc41694f3c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Set your Google Cloud Storage bucket name\n",
    "BUCKET_NAME=\"gs://qwiklabs-gcp-03-c75e2f9727f1\"\n",
    "\n",
    "# Array of top-level directory names you want to create\n",
    "TOP_LEVEL_DIRECTORIES=(\"embeddings-stackoverflow\")\n",
    "\n",
    "# Loop through the top-level array and create directories\n",
    "for TOP_LEVEL_DIRECTORY in \"${TOP_LEVEL_DIRECTORIES[@]}\"; do\n",
    "  gsutil -m cp -r /dev/null \"$BUCKET_NAME/$TOP_LEVEL_DIRECTORY/\"\n",
    "\n",
    "  # Array of subdirectory names you want to create inside the top-level directory\n",
    "  SUBDIRECTORIES=(\"html\")\n",
    "\n",
    "  # Loop through the subdirectories array and create subdirectories inside the top-level directory\n",
    "  for SUBDIRECTORY in \"${SUBDIRECTORIES[@]}\"; do\n",
    "    gsutil -m cp -r /dev/null \"$BUCKET_NAME/$TOP_LEVEL_DIRECTORY/$SUBDIRECTORY/\"\n",
    "  done\n",
    "done\n",
    "\n",
    "echo \"Directories created successfully.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b585441-2f28-4070-822f-a097549bf1bf",
   "metadata": {},
   "source": [
    "Create function that scrapes the content of a question page. If the request is successful and the response contains content, upload the HTML content of the question page to GCS. Then return the GCS URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a74a2-5d95-43f4-abec-54cba8b4e790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JSONL_MIME_TYPE = \"application/jsonl\"\n",
    "HTML_MIME_TYPE = \"text/html\"\n",
    "\n",
    "BUCKET_NAME = \"qwiklabs-gcp-03-c75e2f9727f1\"\n",
    "DIRECTORY = \"embeddings-stackoverflow\"\n",
    "BLOB_PREFIX = f\"{DIRECTORY}/html/\"\n",
    "\n",
    "GCS_URI_PREFIX = f\"gs://{BUCKET_NAME}/{BLOB_PREFIX}\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "\n",
    "def scrape_question(question_url: str) -> str:\n",
    "    response = requests.get(question_url)\n",
    "\n",
    "    if response.status_code != 200 or not response.content:\n",
    "        print(f\"URL: {question_url} Code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Scraping {question_url}\")\n",
    "\n",
    "    link_title = response.url.split(\"/\")[-1] + \".html\"\n",
    "    gcs_uri = f\"{GCS_URI_PREFIX}{link_title}\"\n",
    "\n",
    "    # Upload HTML to Google Cloud Storage\n",
    "    blob = bucket.blob(f\"{BLOB_PREFIX}{link_title}\")\n",
    "    blob.upload_from_string(response.content, content_type=HTML_MIME_TYPE)\n",
    "    time.sleep(1)\n",
    "    return gcs_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83fa40-7d7c-4ae6-98f2-b7877936e18d",
   "metadata": {},
   "source": [
    "Perform the scraping. This could take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e64d39-ec27-4e34-9ae7-7de878b9ca07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the published URL from the ID\n",
    "QUESTION_BASE_URL = \"https://stackoverflow.com/questions/\"\n",
    "df[\"question_url\"] = df[\"id\"].apply(lambda x: f\"{QUESTION_BASE_URL}{x}\")\n",
    "\n",
    "# Scrape HTML from stackoverflow.com and upload to GCS\n",
    "df[\"gcs_uri\"] = df[\"question_url\"].apply(scrape_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b934a-1346-4e24-9203-42a89c300242",
   "metadata": {},
   "source": [
    "## Restructure the Embeddings Data to Required JSONL for Vertex AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104527e1-5d82-4781-91fc-c1994c8f53f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_FIELD_NAME = \"embedding_vector\"\n",
    "\n",
    "def format_row(row):\n",
    "    return {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"content\": {\"mimeType\": HTML_MIME_TYPE, \"uri\": row[\"gcs_uri\"]},\n",
    "        \"structData\": {\n",
    "            EMBEDDINGS_FIELD_NAME: row[\"embedding\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"body\": row[\"body\"],\n",
    "            \"question_url\": row[\"question_url\"],\n",
    "            \"answer_count\": row[\"answer_count\"],\n",
    "            \"creation_date\": row[\"creation_date\"],\n",
    "            \"score\": row[\"score\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "vais_embeddings = (\n",
    "    df.apply(format_row, axis=1)\n",
    "    .to_json(orient=\"records\", lines=True, force_ascii=False)\n",
    "    .replace(\"\\/\", \"/\")  # To prevent escaping the / characters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66c8e5-08ab-4721-9491-72c2c131f8c6",
   "metadata": {},
   "source": [
    "## Upload the JSONL to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558b97d-25f5-4b15-aad3-6a45518803b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jsonl_filename = f\"{DIRECTORY}/vais_embeddings.jsonl\"\n",
    "embeddings_file = f\"gs://{BUCKET_NAME}/{jsonl_filename}\"\n",
    "\n",
    "blob = bucket.blob(jsonl_filename)\n",
    "blob.upload_from_string(vais_embeddings, content_type=JSONL_MIME_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f171c2c-a03c-4bc4-a43a-c32c761ec91f",
   "metadata": {},
   "source": [
    "## Setup Client Options for Interacting with Vertex AI Discovery Engine Service\n",
    "\n",
    "Here we define the API endpoint based on the provided `DATA_STORE_LOCATION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b98a3-fdbe-47c5-9b7a-faf9e0d06fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_STORE_LOCATION = \"global\"\n",
    "\n",
    "client_options = (\n",
    "    ClientOptions(api_endpoint=f\"{DATA_STORE_LOCATION}-discoveryengine.googleapis.com\")\n",
    "    if DATA_STORE_LOCATION != \"global\"\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b232e-ff9e-407b-8b1a-dfc6f73700a1",
   "metadata": {},
   "source": [
    "## Define Funtions for Interacting with Discovery Engine Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e98bd-1431-4f6e-8cc3-81bec99a95f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_store(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    data_store = discoveryengine.DataStore(\n",
    "        display_name=data_store_name,\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        content_config=\"CONTENT_REQUIRED\",\n",
    "        solution_types=[\"SOLUTION_TYPE_SEARCH\"],\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateDataStoreRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        data_store=data_store,\n",
    "        data_store_id=data_store_id,\n",
    "    )\n",
    "    operation = client.create_data_store(request=request)\n",
    "\n",
    "    try:\n",
    "        operation.result()\n",
    "    except GoogleAPICallError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def update_schema(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "):\n",
    "    client = discoveryengine.SchemaServiceClient(client_options=client_options)\n",
    "\n",
    "    schema = discoveryengine.Schema(\n",
    "        name=client.schema_path(project_id, location, data_store_id, \"default_schema\"),\n",
    "        struct_schema={\n",
    "            \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                EMBEDDINGS_FIELD_NAME: {\n",
    "                    \"type\": \"array\",\n",
    "                    \"keyPropertyMapping\": \"embedding_vector\",\n",
    "                    \"dimension\": 768,\n",
    "                    \"items\": {\"type\": \"number\"},\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "    operation = client.update_schema(\n",
    "        request=discoveryengine.UpdateSchemaRequest(schema=schema)\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "\n",
    "    response = operation.result()\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "\n",
    "\n",
    "def import_documents(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    gcs_uri: str,\n",
    "):\n",
    "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine branch.\n",
    "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
    "    parent = client.branch_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.ImportDocumentsRequest(\n",
    "        parent=parent,\n",
    "        gcs_source=discoveryengine.GcsSource(input_uris=[gcs_uri]),\n",
    "        # Options: `FULL`, `INCREMENTAL`\n",
    "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.FULL,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.import_documents(request=request)\n",
    "\n",
    "\n",
    "def create_engine(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    config = discoveryengine.Engine.SearchEngineConfig(\n",
    "        search_tier=\"SEARCH_TIER_ENTERPRISE\", search_add_ons=[\"SEARCH_ADD_ON_LLM\"]\n",
    "    )\n",
    "\n",
    "    engine = discoveryengine.Engine(\n",
    "        display_name=data_store_name,\n",
    "        solution_type=\"SOLUTION_TYPE_SEARCH\",\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        data_store_ids=[data_store_id],\n",
    "        search_engine_config=config,\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateEngineRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        engine=engine,\n",
    "        engine_id=engine.display_name,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_engine(request=request)\n",
    "    response = operation.result(timeout=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62701a4-c0cd-40d8-ad4a-4a07b51660fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_STORE_NAME = \"stackoverflow-embeddings\"\n",
    "DATA_STORE_ID = f\"{DATA_STORE_NAME}-id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b526e1-3975-4d30-8ddc-a54acbcb6c4f",
   "metadata": {},
   "source": [
    "Initialize and configure a search application in Google Cloud Vertex AI Discovery Engine, including creating a data store, updating its schema for embeddings, importing documents, and creating a search engine attached to the data store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9f9b6-1b00-4072-919f-d3e92e4d7f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Data Store\n",
    "create_data_store(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_NAME, DATA_STORE_ID)\n",
    "\n",
    "# Update the Data Store Schema for embeddings\n",
    "update_schema(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_ID)\n",
    "\n",
    "# Import the embeddings JSONL file\n",
    "import_documents(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_ID, embeddings_file)\n",
    "\n",
    "# Create a Search App and attach the Data Store\n",
    "create_engine(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_NAME, DATA_STORE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d15929-e2e8-40f6-8c83-baf0b10fbd3a",
   "metadata": {},
   "source": [
    "## Set the Embedding Specification for the Data Store\n",
    "\n",
    "We will use:\n",
    "`0.5 * relevance_score`.\n",
    "\n",
    "The client libraries do not support this, so we will use the `requests` module to make a REST request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a461ef-ed80-4577-8d8e-2d7852cb4195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "access_token = (\n",
    "    subprocess.check_output([\"gcloud\", \"auth\", \"print-access-token\"])\n",
    "    .decode(\"utf-8\")\n",
    "    .strip()\n",
    ")\n",
    "\n",
    "response = requests.patch(\n",
    "    url=f\"https://discoveryengine.googleapis.com/v1alpha/projects/{PROJECT_ID}/locations/{DATA_STORE_LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/servingConfigs/default_search?updateMask=embeddingConfig,rankingExpression\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        \"X-Goog-User-Project\": PROJECT_ID,\n",
    "    },\n",
    "    json={\n",
    "        \"name\": f\"projects/{PROJECT_ID}/locations/{DATA_STORE_LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/servingConfigs/default_search\",\n",
    "        \"embeddingConfig\": {\"fieldPath\": EMBEDDINGS_FIELD_NAME},\n",
    "        \"ranking_expression\": \"0.5 * relevance_score\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c227d62-56f3-43b3-baa0-c7a6c0ad4b40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test the Search Application\n",
    "\n",
    "Define a function named search_data_store that performs a search operation on a Google Cloud Vertex AI Discovery Engine data store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff338e8-ffd0-44bd-8981-66ac529fc858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_data_store(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    search_query: str,\n",
    ") -> List[discoveryengine.SearchResponse]:\n",
    "    # Create a client\n",
    "    client = discoveryengine.SearchServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine serving config\n",
    "    # e.g. projects/{project_id}/locations/{location}/dataStores/{data_store_id}/servingConfigs/{serving_config_id}\n",
    "    serving_config = client.serving_config_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        serving_config=\"default_config\",\n",
    "    )\n",
    "\n",
    "    # Optional: Configuration options for search\n",
    "    # Refer to the `ContentSearchSpec` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest.ContentSearchSpec\n",
    "    content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(\n",
    "        # For information about snippets, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/snippets\n",
    "        snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(\n",
    "            return_snippet=True\n",
    "        ),\n",
    "        # For information about search summaries, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/get-search-summaries\n",
    "        summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "            summary_result_count=5,\n",
    "            include_citations=True,\n",
    "            ignore_adversarial_query=True,\n",
    "            ignore_non_summary_seeking_query=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Refer to the `SearchRequest` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest\n",
    "    request = discoveryengine.SearchRequest(\n",
    "        serving_config=serving_config,\n",
    "        query=search_query,\n",
    "        page_size=10,\n",
    "        content_search_spec=content_search_spec,\n",
    "        query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n",
    "            condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n",
    "        ),\n",
    "        spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = client.search(request)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fe145-c7a4-4e5b-8e6c-efc525ad411e",
   "metadata": {},
   "source": [
    "Perform a search operation on a Google Cloud Vertex AI Discovery Engine data store using a specified search query and print the summary text of the search response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a588869-0c76-4a63-9f90-2b88251471e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_query = \"How do I create an array in Java?\"\n",
    "\n",
    "response = search_data_store(\n",
    "    PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_ID, search_query\n",
    ")\n",
    "\n",
    "print(f\"Summary: {response.summary.summary_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02a6b0-b508-4ed4-9c9a-ad23e56d49ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
